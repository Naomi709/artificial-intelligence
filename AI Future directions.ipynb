{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4b18abd-296a-490c-b91f-afc175d73553",
   "metadata": {},
   "source": [
    "**\n",
    "### **Q1: Explain how Edge AI reduces latency and enhances privacy compared to cloud-based AI. Provide a real-world example (e.g., autonomous dre**\n",
    "\n",
    "* ge AI** refers to running AI models directly on local devices (like smartphones, sensors, or autonomous drones) rather than relying on centralized cloud servers. This approach provides two key adv\n",
    "s:\n",
    "\n",
    "* **Reduc Lency**:\n",
    "  Processing data on the device eliminates the need to send information back and forth to a remote server. This enables real-time or near-instant decision-making, which is crucial for time-sensitive applications like autonomous drones avoiding obstacles or real-time language translation on mobilices.\n",
    "\n",
    "* **EnhcePrivacy**:\n",
    "  Data stays on the local device, reducing exposure to third-party servers. This is especially valuable in healthcare (e.g., wearable health trackers) or security applications (e.g., smart home cameras), where sensitive personal data can be processed locally without cloud transmion risks.\n",
    "\n",
    "**Re-worlExample**:\n",
    "In **tonomous drones**, Edge AI processes video feeds directly on-board to detect obstacles, navigate, and respond in real time without waiting for cloud server instructions. This allows drones to operate in remote areas without network coverage while protecting captured video data from potl brehes.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q2: Compare Quantum AI and classical AI in solving optimization problems. What industries could benefit srom Quantum ?**\n",
    "\n",
    "**Classical AI** uses traditional computing (binary bits) to process data sequentially. Optimization problems (e.g., finding the best delivery routes) are solved using techniques like gradient descent or heuristics, but complexity grows qkly as datscales.\n",
    "\n",
    "**antum AI**, levering **quantum computing**, uses quantum bits (qubits) that can exist in multiple states simultaneously (superposition). This enables parallel exploration of solution paths, potentially solving complex optimization tasks exponentially fasteran classic ethods.\n",
    "\n",
    "**Comparison**:\n",
    "\n",
    "| Aspect                | Classical AI                               | Quantum AI                            |\n",
    "| --------------------- | ------------------------------------------ | ------------------------------------- |\n",
    "| Data Representation   | Binary bits (0/1)                          | Qubits (superposition & entanglement) |\n",
    "| Problem Solving Speed | Sequential, can be slow for large problems | Potential exponential speedup         |\n",
    "| Maturity              | Mature, widely applied                     | Emergingexperimental                |\n",
    "\n",
    "*ndes that could benefit mo**:\n",
    "\n",
    "* **Logistics & Supply Chain**: Rout\n",
    "imization, wareuse management.\n",
    "* **Pharmaceuticals**: Driscovervia molecule simulation.\n",
    "* **Finance**: Portf optimizationnd fraud detection.\n",
    "* **Energy Sector**: Power grid optimization.\n",
    "\n",
    "While practical quantum AI is still in early stages, industries with large-scale,lex pblems stand to gain the most.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q3: Discuss the societal impact of Human-AI collaboration in healthcare. How might itsform roles like radiogists or nurses?**\n",
    "\n",
    "**Human-AI collaboration** in healthcare aims to augment rather than replace medical professionals, combining mace precision with magment and emth\n",
    "\n",
    "**Potential Impacts**:\n",
    "\n",
    "* **Radiologists**:\n",
    "  AI can analyze medical images (X-rays, MRIs) faster and flag potential issues like tumors with high accuracy. Radiologists can shift from routine analysis to focusing on complex cases, verifyinoutput a making nuanced clinical decisions.\n",
    "\n",
    "* **Nurses**:\n",
    "  AI-powered systems can monitor patient vitals continuously and detect early warning signs, assisting nurses in prioritizing care. Automation of routine documentation can free up nurses to fo more on patient interactnand compassionate care.\n",
    "\n",
    "**Broader Societal Benefits**:\n",
    "\n",
    "* Improved diagnostic accuracy.\n",
    "* Faster patient care.\n",
    "* Reduced workload and burnout for healthcare workers.\n",
    "* Ensued human oversight to maintain ethical, empathetic healthcare.\n",
    "\n",
    "In essence, Human-AI collaboration transforms healthcare roles into more decision-focuson, markdown formatting for your notebook, or help adding citations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef644720-d101-46d2-a87a-04b68b496acf",
   "metadata": {},
   "source": [
    "### 2. Case Study Critique: AI in Smart Cities\n",
    "Topic: AI-IoT for Traffic Management\n",
    "Focus: How integrating AI with IoT improves urban sustainability and key challenges.\n",
    "How AI-IoT Integration Improves Urban Sustainability\n",
    "AI-IoT integration allows real-time data collection and intelligent analysis, transforming traffic management systems into responsive, adaptive networks. Benefits include:\n",
    "Reduced Traffic Congestion:\n",
    "IoT sensors (e.g., traffic cameras, GPS in vehicles) feed data to AI systems that predict congestion patterns and dynamically adjust traffic signals. This reduces idle time at intersections, optimizing traffic flow and decreasing emissions.\n",
    "Lower Air Pollution:\n",
    "By reducing stop-and-go traffic, AI-controlled systems help cut fuel consumption and carbon emissions, contributing to cleaner urban air.\n",
    "Efficient Public Transport:\n",
    "AI algorithms analyze commuter data, helping cities optimize bus routes and schedules based on real demand, encouraging public transport use over private cars.\n",
    "Energy Savings:\n",
    "Smart streetlights powered by IoT can adjust brightness based on pedestrian/vehicle presence, saving electricity.\n",
    "In short, AI-IoT systems promote sustainable urban environments by reducing pollution, conserving energy, and optimizing resource use.\n",
    "Two Key Challenges\n",
    "Data Security & Privacy Risks:\n",
    "Large volumes of real-time data (vehicle locations, traffic flows, personal movement patterns) raise security concerns. Without strong encryption and access control, this sensitive data can be intercepted, misused, or lead to surveillance risks.\n",
    "Infrastructure Costs & Legacy Systems:\n",
    "Deploying IoT sensors across an entire city and upgrading legacy traffic systems requires significant investment. Integration challenges arise when connecting AI systems with outdated infrastructure, potentially slowing adoption in resource-limited cities.\n",
    "Conclusion:\n",
    "While AI-IoT integration offers major sustainability benefits for smart cities, addressing security vulnerabilities and infrastructure limitations is critical for scalable, ethical implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07dd72d-4dd3-4599-abfa-8fb9e2ea61f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\KARIS\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import Libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:88\u001b[0m\n\u001b[0;32m     86\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     92\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     93\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you need help, create an issue \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     94\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     95\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand include the entire stack trace above this error message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\KARIS\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee2b251-fe97-48f3-a983-b9af4897b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"dataset_path\",  \n",
    "    image_size=(128, 128),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "class_names = dataset.class_names\n",
    "train_ds = dataset.take(80)\n",
    "val_ds = dataset.skip(80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6d584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(128, 128, 3)),\n",
    "    layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c191771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, validation_data=val_ds, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cf4898",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['val_accuracy'][-1]\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3aff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('recycle_classifier.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e083d29e",
   "metadata": {},
   "source": [
    "Edge AI Benefits for Real-Time Applications\n",
    "Low Latency:\n",
    "Since inference occurs directly on devices (like smartphones or Raspberry Pi), responses are immediateâ€”ideal for applications like sorting waste in real-time.\n",
    "\n",
    "Improved Privacy:\n",
    "No need to send sensitive images to the cloud; data stays on the local device.\n",
    "\n",
    "Offline Functionality:\n",
    "Devices like drones, waste sorting machines, or robots can work without constant internet access.\n",
    "\n",
    "Energy Efficiency:\n",
    "TensorFlow Lite models are optimized to use minimal device resources.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b1cf66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
