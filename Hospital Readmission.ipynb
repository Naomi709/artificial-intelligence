{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20e1e6a-cfc0-4d71-9c12-27de8104e11f",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Problem Definition\n",
    "Hypothetical AI Problem:\n",
    "Predicting hospital patient readmission within 30 days of discharge.\n",
    "\n",
    "Objectives:\n",
    "Reduce readmission rates to improve patient outcomes.\n",
    "Identify high-risk patients early for targeted interventions.\n",
    "Optimize hospital resource allocation based on predicted risk.\n",
    "\n",
    "Stakeholders:\n",
    "Hospital management and administrators.\n",
    "Clinicians and healthcare providers.\n",
    "\n",
    "Key Performance Indicator (KPI):\n",
    "Percentage reduction in 30-day readmission rates after AI system implementation.\n",
    "\n",
    "### 2. Data Collection & Preprocessing \n",
    "Data Sources:\n",
    "Electronic Health Records (EHR) containing patient medical history.\n",
    "Demographic data such as age, gender, and socioeconomic status.\n",
    "\n",
    "Potential Bias:\n",
    "Patients from underrepresented groups (e.g., rural areas) may be missing or underrepresented in the data, leading to biased predictions.\n",
    "\n",
    "processing Steps:\n",
    "\n",
    "1. Handling missing data using imputation (mean for numerical, mode for categorical).\n",
    "2. Encoding categorical variables into numeric formats (e.g., one-hot encoding or label encoding).\n",
    "3. Normalizing numerical features such as age and hospital stay length to a common scale.\n",
    "4. \n",
    "### 3. Model Development\n",
    "Model Choice:\n",
    "Random Forest classifier — because it handles tabular data well, is robust to missing values, and offers good interpretability.\n",
    "Data Splitting:\n",
    "70% training data to learn patterns.\n",
    "15% validation data to tune hyperparameters.\n",
    "15% testing data to evaluate final model performance.\n",
    "\n",
    "Hyperparameters to Tune:\n",
    "Number of trees (`n_estimators`): Affects model stability and performance.\n",
    "Maximum depth of trees (`max_depth`): Controls overfitting vs. underfitting balance.\n",
    "\n",
    "### 4. Evaluation & Deployment\n",
    "Evaluation Metrics:\n",
    "F1-Score: Balances precision and recall, important for medical decisions.\n",
    "ROC-AUC: Measures overall ability to distinguish between readmission and non-readmission.\n",
    "\n",
    "Concept Drift:\n",
    "Concept drift refers to changes in data patterns over time (e.g., new treatment protocols) that reduce model accuracy. Monitoring involves regularly evaluating model performance on new data and retraining as needed.\n",
    "\n",
    "Deployment Challenge:\n",
    "Ensuring the system can scale to handle large volumes of predictions in real-time without slowing down hospital workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8584c71d-a728-4581-9a22-2361e306f8c5",
   "metadata": {},
   "source": [
    "Case Study Application\n",
    "1. Problem Scope\n",
    "Problem:\n",
    "Develop an AI system to predict the risk of patient readmission within 30 days after hospital discharge.\n",
    "Objectives:\n",
    "Identify patients at high risk of readmission early.\n",
    "Reduce unnecessary readmissions and improve patient care.\n",
    "Assist hospital resource planning and management.\n",
    "Stakeholders:\n",
    "Hospital administrators and management.\n",
    "Doctors, nurses, and discharge coordinators.\n",
    "\n",
    "2. Data Strategy\n",
    "Data Sources:\n",
    "Electronic Health Records (EHR) containing medical history, diagnoses, lab results, and treatments.\n",
    "Patient demographic data including age, gender, insurance status, and socioeconomic factors.\n",
    "Ethical Concerns:\n",
    "Patient Privacy: Ensuring sensitive health data is securely stored and only accessed by authorized personnel.\n",
    "Bias and Fairness: Avoiding discrimination against certain groups due to underrepresentation in data or biased historical practices.\n",
    "Preprocessing Pipeline:\n",
    "Data Cleaning: Handle missing values using imputation strategies (mean for numerical, mode for categorical).\n",
    "Feature Engineering:\n",
    "Create new features like number of prior admissions, length of stay, and presence of chronic diseases.\n",
    "Aggregate lab test results over time to capture trends.\n",
    "Encoding & Scaling: Convert categorical variables into numerical form (e.g., label encoding for gender), normalize numerical features for uniformity.\n",
    "Anonymization: Remove personally identifiable information (PII) to protect patient privacy.\n",
    "\n",
    "3. Model Development\n",
    "Model Selection:\n",
    "Gradient Boosted Trees (e.g., XGBoost) because it performs well with structured medical data and can handle non-linear relationships effectively.\n",
    "Confusion Matrix (Hypothetical):\n",
    "Predicted Readmit\tPredicted Not Readmit\n",
    "Actual Readmit\t80\t20\n",
    "Actual Not Readmit\t30\t170\n",
    "Calculations:\n",
    "Precision = TP / (TP + FP) = 80 / (80 + 30) = 0.73\n",
    "Recall = TP / (TP + FN) = 80 / (80 + 20) = 0.80\n",
    "\n",
    "4. Deployment\n",
    "Integration Steps:\n",
    "Develop a REST API to serve model predictions.\n",
    "Connect the API securely to the hospital’s Electronic Medical Record (EMR) system.\n",
    "Implement user authentication and access control.\n",
    "Schedule regular retraining using new patient data to keep the model updated.\n",
    "Healthcare Compliance (HIPAA):\n",
    "Use encryption for data in transit and at rest.\n",
    "Maintain audit logs of data access and predictions.\n",
    "Ensure patient consent is obtained for data use.\n",
    "Follow strict access controls and data anonymization protocols.\n",
    "\n",
    "5. Optimization\n",
    "Addressing Overfitting:\n",
    "Apply regularization techniques like L1/L2 penalties during model training.\n",
    "Use cross-validation to tune hyperparameters.\n",
    "Limit tree depth and increase minimum samples per leaf in tree-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa649bc-b86d-4193-99f1-829c0946625e",
   "metadata": {},
   "source": [
    "Critical Thinking \n",
    "Ethics & Bias\n",
    "Impact of Biased Training Data:\n",
    "If the training data underrepresents certain patient groups (e.g., elderly, minorities, or low-income populations), the AI model may make less accurate predictions for those groups. This could lead to worse patient outcomes such as missed readmission risks or unnecessary interventions, increasing healthcare disparities.\n",
    "\n",
    "Strategy to Mitigate Bias:\n",
    "Use stratified sampling to ensure balanced representation of all relevant patient groups in the training dataset. Additionally, perform fairness audits to identify and correct biased model behavior before deployment.\n",
    "\n",
    "Trade-offs\n",
    "Interpretability vs. Accuracy:\n",
    "In healthcare, models need to be interpretable so clinicians can trust and understand AI-driven decisions. Sometimes simpler models (e.g., decision trees, logistic regression) are preferred for their transparency even if they offer slightly lower accuracy. Complex models like deep neural networks may be more accurate but are often “black boxes,” making it harder to justify decisions in critical settings.\n",
    "\n",
    "Impact of Limited Computational Resources:\n",
    "With limited hardware, the hospital might choose lightweight models such as Random Forests or Logistic Regression instead of computationally intensive deep learning models. This ensures faster predictions and easier integration but may sacrifice some accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91464c6-638b-45dc-b08e-9fb360845bc1",
   "metadata": {},
   "source": [
    "Reflection & Workflow Diagram\n",
    "Reflection\n",
    "Most Challenging Part:\n",
    "The most challenging part of the AI development workflow was managing ethical concerns—especially ensuring patient privacy and reducing bias in the data. Healthcare data is sensitive, and balancing data utility with privacy requirements while maintaining fairness was complex.\n",
    "\n",
    "Improvement with More Time/Resources:\n",
    "With more time and resources, I would invest in deeper exploratory data analysis and implement advanced bias detection and mitigation techniques. Additionally, I would build a more comprehensive monitoring system post-deployment to catch issues like concept drift early.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a81044-f561-4ea8-bddd-83d88df8b825",
   "metadata": {},
   "source": [
    "Problem Definition\n",
    "        ↓\n",
    "Data Collection\n",
    "        ↓\n",
    "Data Preprocessing\n",
    "        ↓\n",
    "Model Development\n",
    "        ↓\n",
    "Model Evaluation\n",
    "        ↓\n",
    "Model Deployment\n",
    "        ↓\n",
    "Monitoring & Maintenance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5595cf5-b65a-4e64-8f33-d58babcd5831",
   "metadata": {},
   "source": [
    "# Hospital_Readmission_RF.ipynb\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 1. Load Dataset (Example: replace with your actual dataset path)\n",
    "# For demonstration, let's create a sample dataset\n",
    "data = {\n",
    "    'age': [65, 50, 80, 45, 33, 70, np.nan, 60, 55, 40],\n",
    "    'gender': ['M', 'F', 'F', 'M', 'M', 'F', 'M', 'F', np.nan, 'M'],\n",
    "    'previous_admissions': [3, 0, 5, 1, 0, 4, 2, 1, 0, 0],\n",
    "    'chronic_condition': ['Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No'],\n",
    "    'readmitted': [1, 0, 1, 0, 0, 1, 1, 0, 0, 0]  # Target variable\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. Handle Missing Values\n",
    "imputer_num = SimpleImputer(strategy='mean')\n",
    "df['age'] = imputer_num.fit_transform(df[['age']])\n",
    "\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "df['gender'] = imputer_cat.fit_transform(df[['gender']])\n",
    "\n",
    "# 3. Encode Categorical Variables\n",
    "le_gender = LabelEncoder()\n",
    "df['gender'] = le_gender.fit_transform(df['gender'])\n",
    "\n",
    "le_chronic = LabelEncoder()\n",
    "df['chronic_condition'] = le_chronic.fit_transform(df['chronic_condition'])\n",
    "\n",
    "# 4. Prepare Features and Target\n",
    "X = df.drop('readmitted', axis=1)\n",
    "y = df['readmitted']\n",
    "\n",
    "# 5. Split the Data (70% train, 15% validation, 15% test)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42, stratify=y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.1765, random_state=42, stratify=y_train_full)\n",
    "# 0.1765 ≈ 15% of original data to validation\n",
    "\n",
    "# 6. Train Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 7. Validate the Model\n",
    "y_val_pred = rf.predict(X_val)\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# 8. Evaluate on Test Set\n",
    "y_test_pred = rf.predict(X_test)\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# ROC AUC Score\n",
    "y_test_prob = rf.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "print(f\"ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# 9. Feature Importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "feat_importances.sort_values().plot(kind='barh', figsize=(8, 5))\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd87822-5e56-46e6-9a9f-ee09ecbd6e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
